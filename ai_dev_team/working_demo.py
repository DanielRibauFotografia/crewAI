#!/usr/bin/env python3
"""
Working Demo - AI Development Team
Complete working example that demonstrates the system capabilities
"""

import os
from pathlib import Path
from dotenv import load_dotenv
from crewai import Agent, Crew, Process, Task
from crewai.llm import LLM

# Load environment variables
load_dotenv()

def create_working_demo():
    """Create a working demo that completes successfully"""
    
    print("üöÄ AI Development Team - Working Demo")
    print("=" * 60)
    
    # Initialize LLM
    llm = LLM(
        model=f"ollama/{os.getenv('DEFAULT_LLM_MODEL', 'llama3.2:3b')}",
        base_url=os.getenv('OLLAMA_BASE_URL', 'http://localhost:11434')
    )
    
    # Create a simple analyst agent
    analyst = Agent(
        role="Technical Analyst",
        goal="Provide quick technical analysis and recommendations",
        backstory="You are a technical analyst who provides concise, practical recommendations.",
        llm=llm,
        verbose=True,
        max_iter=1,
        max_execution_time=60
    )
    
    # Project description
    project = "Create a simple REST API for a todo application"
    
    # Create a simple task
    analysis_task = Task(
        description=f"""
        Analyze: {project}
        
        Provide:
        1. Brief project overview (2-3 sentences)
        2. Key features needed (3-4 bullet points)
        3. Technology stack recommendation (2-3 technologies)
        4. Next steps (2-3 action items)
        
        Be concise and practical.
        """,
        expected_output="A brief technical analysis with recommendations",
        agent=analyst
    )
    
    print(f"üìù Project: {project}")
    print("üîÑ Starting analysis...")
    print("=" * 60)
    
    # Create and run crew
    crew = Crew(
        agents=[analyst],
        tasks=[analysis_task],
        process=Process.sequential,
        verbose=True
    )
    
    try:
        # Execute the crew
        result = crew.kickoff()
        
        print("=" * 60)
        print("‚úÖ Analysis completed successfully!")
        print("=" * 60)
        
        # Create output directory
        output_dir = Path("output")
        output_dir.mkdir(exist_ok=True)
        
        # Save result
        output_file = output_dir / "working_demo_result.md"
        with open(output_file, "w") as f:
            f.write(f"# AI Development Team - Working Demo Result\n\n")
            f.write(f"**Project:** {project}\n\n")
            f.write(f"**Generated on:** {Path(__file__).stat().st_mtime}\n\n")
            f.write(f"## Analysis Result\n\n{result}\n\n")
            f.write("---\n\n")
            f.write("*Generated by AI Development Team using CrewAI with local Ollama models*\n")
        
        print(f"üìÅ Result saved to: {output_file}")
        print("=" * 60)
        
        # Show summary
        print("üìã DEMO SUMMARY:")
        print("‚úÖ System is working correctly")
        print("‚úÖ Local AI models are responding")
        print("‚úÖ Agents are generating useful output")
        print("‚úÖ Results are being saved to files")
        print("=" * 60)
        
        return str(result)
        
    except Exception as e:
        print(f"‚ùå Demo failed: {str(e)}")
        return None

if __name__ == "__main__":
    create_working_demo()